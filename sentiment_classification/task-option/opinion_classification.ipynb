{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1003696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-06-24 21:13:03--  https://dataset-bj.cdn.bcebos.com/qianyan/COTE-BD.zip\n",
      "正在解析主机 dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)... 114.232.92.35, 114.80.30.35\n",
      "正在连接 dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)|114.232.92.35|:443... 已连接。\n",
      "已发出 HTTP 请求，正在等待回应... 200 OK\n",
      "长度： 1182741 (1.1M) [application/zip]\n",
      "正在保存至: “COTE-BD.zip”\n",
      "\n",
      "COTE-BD.zip         100%[===================>]   1.13M  6.01MB/s    用时 0.2s    \n",
      "\n",
      "2021-06-24 21:13:03 (6.01 MB/s) - 已保存 “COTE-BD.zip” [1182741/1182741])\n",
      "\n",
      "--2021-06-24 21:13:03--  https://dataset-bj.cdn.bcebos.com/qianyan/COTE-MFW.zip\n",
      "正在解析主机 dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)... 114.232.92.35, 114.80.30.35\n",
      "正在连接 dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)|114.232.92.35|:443... 已连接。\n",
      "已发出 HTTP 请求，正在等待回应... 200 OK\n",
      "长度： 4872264 (4.6M) [application/zip]\n",
      "正在保存至: “COTE-MFW.zip”\n",
      "\n",
      "COTE-MFW.zip        100%[===================>]   4.65M  9.41MB/s    用时 0.5s    \n",
      "\n",
      "2021-06-24 21:13:04 (9.41 MB/s) - 已保存 “COTE-MFW.zip” [4872264/4872264])\n",
      "\n",
      "--2021-06-24 21:13:04--  https://dataset-bj.cdn.bcebos.com/qianyan/COTE-DP.zip\n",
      "正在解析主机 dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)... 114.232.92.35, 114.80.30.35\n",
      "正在连接 dataset-bj.cdn.bcebos.com (dataset-bj.cdn.bcebos.com)|114.232.92.35|:443... 已连接。\n",
      "已发出 HTTP 请求，正在等待回应... 200 OK\n",
      "长度： 4220083 (4.0M) [application/zip]\n",
      "正在保存至: “COTE-DP.zip”\n",
      "\n",
      "COTE-DP.zip         100%[===================>]   4.02M  9.17MB/s    用时 0.4s    \n",
      "\n",
      "2021-06-24 21:13:04 (9.17 MB/s) - 已保存 “COTE-DP.zip” [4220083/4220083])\n",
      "\n",
      "Archive:  ./COTE-BD.zip\n",
      "   creating: ./data/COTE-BD/\n",
      "  inflating: ./data/COTE-BD/train.tsv  \n",
      "   creating: ./data/__MACOSX/\n",
      "   creating: ./data/__MACOSX/COTE-BD/\n",
      "  inflating: ./data/__MACOSX/COTE-BD/._train.tsv  \n",
      "  inflating: ./data/COTE-BD/License.pdf  \n",
      "  inflating: ./data/__MACOSX/COTE-BD/._License.pdf  \n",
      "  inflating: ./data/COTE-BD/test.tsv  \n",
      "  inflating: ./data/__MACOSX/COTE-BD/._test.tsv  \n",
      "  inflating: ./data/__MACOSX/._COTE-BD  \n",
      "Archive:  ./COTE-MFW.zip\n",
      "   creating: ./data/COTE-MFW/\n",
      "  inflating: ./data/COTE-MFW/train.tsv  \n",
      "   creating: ./data/__MACOSX/COTE-MFW/\n",
      "  inflating: ./data/__MACOSX/COTE-MFW/._train.tsv  \n",
      "  inflating: ./data/COTE-MFW/License.pdf  \n",
      "  inflating: ./data/__MACOSX/COTE-MFW/._License.pdf  \n",
      "  inflating: ./data/COTE-MFW/test.tsv  \n",
      "  inflating: ./data/__MACOSX/COTE-MFW/._test.tsv  \n",
      "  inflating: ./data/__MACOSX/._COTE-MFW  \n",
      "Archive:  ./COTE-DP.zip\n",
      "   creating: ./data/COTE-DP/\n",
      "  inflating: ./data/COTE-DP/train.tsv  \n",
      "   creating: ./data/__MACOSX/COTE-DP/\n",
      "  inflating: ./data/__MACOSX/COTE-DP/._train.tsv  \n",
      "  inflating: ./data/COTE-DP/License.pdf  \n",
      "  inflating: ./data/__MACOSX/COTE-DP/._License.pdf  \n",
      "  inflating: ./data/COTE-DP/test.tsv  \n",
      "  inflating: ./data/__MACOSX/COTE-DP/._test.tsv  \n",
      "  inflating: ./data/__MACOSX/._COTE-DP  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#下载数据集\n",
    "!wget https://dataset-bj.cdn.bcebos.com/qianyan/COTE-BD.zip\n",
    "!wget https://dataset-bj.cdn.bcebos.com/qianyan/COTE-MFW.zip\n",
    "!wget https://dataset-bj.cdn.bcebos.com/qianyan/COTE-DP.zip\n",
    "\n",
    "# 解压数据集到 ./data 目录\n",
    "!unzip ./COTE-BD.zip -d ./data/\n",
    "!unzip ./COTE-MFW.zip -d ./data/\n",
    "!unzip ./COTE-DP.zip -d ./data/\n",
    "\n",
    "# 删除压缩包\n",
    "!rm COTE-BD.zip\n",
    "!rm COTE-MFW.zip\n",
    "!rm COTE-DP.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d633148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到数据集字典\n",
    "def open_func(file_path):\n",
    "    return [line.strip() for line in open(file_path, 'r', encoding='utf8').readlines()[1:] if len(line.strip().split('\\t')) >= 2]\n",
    "\n",
    "data_dict = {'cotebd': {'test': open_func('data/COTE-BD/test.tsv'),\n",
    "                        'train': open_func('data/COTE-BD/train.tsv')},\n",
    "             'cotedp': {'test': open_func('data/COTE-DP/test.tsv'),\n",
    "                        'train': open_func('data/COTE-DP/train.tsv')},\n",
    "             'cotemfw': {'test': open_func('data/COTE-MFW/test.tsv'),\n",
    "                        'train': open_func('data/COTE-MFW/train.tsv')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3803d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义数据集\n",
    "from paddle.io import Dataset, DataLoader\n",
    "from paddlenlp.data import Pad, Stack, Tuple\n",
    "import numpy as np\n",
    "label_list = {'B': 0, 'I': 1, 'O': 2}\n",
    "index2label = {0: 'B', 1: 'I', 2: 'O'}\n",
    "\n",
    "# 考虑token_type_id\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=512, for_test=False):\n",
    "        super().__init__()\n",
    "        self._data = data\n",
    "        self._tokenizer = tokenizer\n",
    "        self._max_len = max_len\n",
    "        self._for_test = for_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        samples = self._data[idx].split('\\t')\n",
    "        label = samples[-2]\n",
    "        text = samples[-1]\n",
    "        if self._for_test:\n",
    "            origin_enc = self._tokenizer.encode(text, max_seq_len=self._max_len)['input_ids']\n",
    "            return np.array(origin_enc, dtype='int64')\n",
    "        else:\n",
    "            \n",
    "            # 由于并不是每个字都是一个token，这里采用一种简单的处理方法，先编码label，再编码text中除了label以外的词，最后合到一起\n",
    "            texts = text.split(label)\n",
    "            label_enc = self._tokenizer.encode(label)['input_ids']\n",
    "            cls_enc = label_enc[0]\n",
    "            sep_enc = label_enc[-1]\n",
    "            label_enc = label_enc[1:-1]\n",
    "            \n",
    "            # 合并\n",
    "            origin_enc = []\n",
    "            label_ids = []\n",
    "            for index, text in enumerate(texts):\n",
    "                text_enc = self._tokenizer.encode(text)['input_ids']\n",
    "                text_enc = text_enc[1:-1]\n",
    "                origin_enc += text_enc\n",
    "                label_ids += [label_list['O']] * len(text_enc)\n",
    "                if index != len(texts) - 1:\n",
    "                    origin_enc += label_enc\n",
    "                    label_ids += [label_list['B']] + [label_list['I']] * (len(label_enc) - 1)\n",
    "\n",
    "            origin_enc = [cls_enc] + origin_enc + [sep_enc]\n",
    "            label_ids = [label_list['O']] + label_ids + [label_list['O']]\n",
    "            \n",
    "            # 截断\n",
    "            if len(origin_enc) > self._max_len:\n",
    "                origin_enc = origin_enc[:self._max_len-1] + origin_enc[-1:]\n",
    "                label_ids = label_ids[:self._max_len-1] + label_ids[-1:]\n",
    "            return np.array(origin_enc, dtype='int64'), np.array(label_ids, dtype='int64')\n",
    "\n",
    "\n",
    "def batchify_fn(for_test=False):\n",
    "    if for_test:\n",
    "        return lambda samples, fn=Pad(axis=0, pad_val=tokenizer.pad_token_id): np.row_stack([data for data in fn(samples)])\n",
    "    else:\n",
    "        return lambda samples, fn=Tuple(Pad(axis=0, pad_val=tokenizer.pad_token_id),\n",
    "                                        Pad(axis=0, pad_val=label_list['O'])): [data for data in fn(samples)]\n",
    "\n",
    "\n",
    "def get_data_loader(data, tokenizer, batch_size=32, max_len=512, for_test=False):\n",
    "    dataset = MyDataset(data, tokenizer, max_len, for_test)\n",
    "    shuffle = True if not for_test else False\n",
    "    data_loader = DataLoader(dataset=dataset, batch_size=batch_size, collate_fn=batchify_fn(for_test), shuffle=shuffle)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14af38b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2021-06-24 21:18:59,558] [    INFO]\u001b[0m - Already cached /home/gaojing/.paddlenlp/models/skep_ernie_1.0_large_ch/skep_ernie_1.0_large_ch.pdparams\u001b[0m\n",
      "/home/gaojing/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.weight. classifier.weight is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "/home/gaojing/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py:1297: UserWarning: Skip loading for classifier.bias. classifier.bias is not found in the provided dict.\n",
      "  warnings.warn((\"Skip loading for {}. \".format(key) + str(err)))\n",
      "\u001b[32m[2021-06-24 21:19:04,192] [    INFO]\u001b[0m - Found /home/gaojing/.paddlenlp/models/skep_ernie_1.0_large_ch/skep_ernie_1.0_large_ch.vocab.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 模型搭建\n",
    "\n",
    "# 载入模型和Tokenizer\n",
    "import paddlenlp\n",
    "from paddlenlp.transformers import SkepForTokenClassification, SkepTokenizer\n",
    "import paddle\n",
    "from paddle.static import InputSpec\n",
    "from paddlenlp.metrics import Perplexity\n",
    "\n",
    "# 模型和分词\n",
    "model = SkepForTokenClassification.from_pretrained('skep_ernie_1.0_large_ch', num_classes=3)\n",
    "tokenizer = SkepTokenizer.from_pretrained('skep_ernie_1.0_large_ch')\n",
    "\n",
    "# 参数设置\n",
    "data_name = 'cotemfw'  # 更改此选项改变数据集\n",
    "\n",
    "## 训练相关\n",
    "epochs = 1\n",
    "learning_rate = 2e-5\n",
    "batch_size = 24\n",
    "max_len = 512\n",
    "\n",
    "## 数据相关\n",
    "train_dataloader = get_data_loader(data_dict[data_name]['train'], tokenizer, batch_size, max_len, for_test=False)\n",
    "\n",
    "input = InputSpec((-1, -1), dtype='int64', name='input')\n",
    "label = InputSpec((-1, -1, 3), dtype='int64', name='label')\n",
    "model = paddle.Model(model, [input], [label])\n",
    "\n",
    "# 模型准备\n",
    "\n",
    "optimizer = paddle.optimizer.Adam(learning_rate=learning_rate, parameters=model.parameters())\n",
    "model.prepare(optimizer, loss=paddle.nn.CrossEntropyLoss(), metrics=[Perplexity()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ca58b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "(Fatal) Operator elementwise_add raises an paddle::memory::allocation::BadAlloc exception.\nThe exception content is\n:ResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 79.500244MB memory on GPU 0, 10.702026GB memory has been allocated and available memory is only 60.562500MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \n\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:79)\n. (at /paddle/paddle/fluid/imperative/tracer.cc:192)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-286613f9fe7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./checkpoints'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/hapi/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, eval_data, batch_size, epochs, eval_freq, log_freq, save_dir, save_freq, verbose, drop_last, shuffle, num_workers, callbacks)\u001b[0m\n\u001b[1;32m   1713\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1715\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1716\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/hapi/model.py\u001b[0m in \u001b[0;36m_run_one_epoch\u001b[0;34m(self, data_loader, callbacks, mode, logs)\u001b[0m\n\u001b[1;32m   2020\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2021\u001b[0m                 outs = getattr(self, mode + '_batch')(data[:len(self._inputs)],\n\u001b[0;32m-> 2022\u001b[0;31m                                                       data[len(self._inputs):])\n\u001b[0m\u001b[1;32m   2023\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2024\u001b[0m                     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/hapi/model.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m   1056\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m         \"\"\"\n\u001b[0;32m-> 1058\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfluid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_dygraph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_info\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/hapi/model.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                 outputs = self.model.network.forward(\n\u001b[0;32m--> 716\u001b[0;31m                     * [to_variable(x) for x in inputs])\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddlenlp/transformers/skep/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m             attention_mask=attention_mask)\n\u001b[0m\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddlenlp/transformers/skep/modeling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, attention_mask)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             token_type_ids=token_type_ids)\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mencoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/nn/layer/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, cache)\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                 output, new_cache = mod(output,\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/nn/layer/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, cache)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_before\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/fluid/dygraph/layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_built\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mforward_post_hook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_post_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/nn/layer/common.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         out = F.linear(\n\u001b[0;32m--> 129\u001b[0;31m             x=input, weight=self.weight, bias=self.bias, name=self.name)\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/nn/functional/common.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(x, weight, bias, name)\u001b[0m\n\u001b[1;32m   1451\u001b[0m                         'transpose_Y', False, \"alpha\", 1)\n\u001b[1;32m   1452\u001b[0m         return dygraph_utils._append_bias_in_dygraph(\n\u001b[0;32m-> 1453\u001b[0;31m             pre_bias, bias, axis=len(x.shape) - 1)\n\u001b[0m\u001b[1;32m   1454\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1455\u001b[0m         \u001b[0mhelper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLayerHelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-153>\u001b[0m in \u001b[0;36m_append_bias_in_dygraph\u001b[0;34m(input, bias, axis, use_mkldnn)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/fluid/wrapped_decorator.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mwrapped_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/fluid/framework.py\u001b[0m in \u001b[0;36m__impl__\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m         assert in_dygraph_mode(\n\u001b[1;32m    224\u001b[0m         ), \"We only support '%s()' in dynamic graph mode, please call 'paddle.disable_static()' to enter dynamic graph mode.\" % func.__name__\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__impl__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/paddlepaddle-gpu-2.1.0/lib/python3.6/site-packages/paddle/fluid/dygraph_utils.py\u001b[0m in \u001b[0;36m_append_bias_in_dygraph\u001b[0;34m(input, bias, axis, use_mkldnn)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     return core.ops.elementwise_add(input, bias, 'axis', axis, 'use_mkldnn',\n\u001b[0;32m---> 63\u001b[0;31m                                     use_mkldnn)\n\u001b[0m",
      "\u001b[0;31mSystemError\u001b[0m: (Fatal) Operator elementwise_add raises an paddle::memory::allocation::BadAlloc exception.\nThe exception content is\n:ResourceExhaustedError: \n\nOut of memory error on GPU 0. Cannot allocate 79.500244MB memory on GPU 0, 10.702026GB memory has been allocated and available memory is only 60.562500MB.\n\nPlease check whether there is any other process using GPU 0.\n1. If yes, please stop them, or start PaddlePaddle on another GPU.\n2. If no, please decrease the batch size of your model. \n\n (at /paddle/paddle/fluid/memory/allocation/cuda_allocator.cc:79)\n. (at /paddle/paddle/fluid/imperative/tracer.cc:192)\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataloader, batch_size=batch_size, epochs=epochs, save_freq=5, save_dir='./checkpoints', log_freq=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40decd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
